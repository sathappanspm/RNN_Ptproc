{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from datetime import timedelta\n",
    "import tensorflow as tf\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/sathappan/workspace/time2event/hawkes/data/all_trades.csv\")\n",
    "df.t = pd.to_datetime(df.t)\n",
    "pp = (df.t - df.t[0]).apply(lambda x: x/np.timedelta64(1, 'm')).value_counts()\n",
    "events = []\n",
    "e = 1.667e-6\n",
    "for t, cnt in pp.iteritems():\n",
    "    base_time = t\n",
    "    for i in range(cnt):\n",
    "        events.append(base_time + e*i)\n",
    "\n",
    "events = np.array(sorted(events))\n",
    "empirical = df.t\n",
    "empirical_counts = empirical.value_counts().resample(rule='1min').sum()\n",
    "events = events[None, :4000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_Ai(arrivals, mask, beta):\n",
    "    tdiff = np.diff(arrivals) * mask[:, 1:]\n",
    "    tdiff = np.exp(tdiff * -beta)\n",
    "    A_i = np.zeros_like(arrivals, dtype=np.float128)\n",
    "    for i in range(tdiff.shape[1]):\n",
    "        #print(i,)\n",
    "        A_i[:, i + 1] = tdiff[:, i] * (1 + A_i[:, i])\n",
    "    return A_i, tdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.ones_like(events)\n",
    "A_i, tempdiff = calc_Ai(events, mask, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_temporal_differences(arrivals, mask):\n",
    "    temporal_diff = np.zeros((arrivals.shape[0], arrivals.shape[1], arrivals.shape[1]))\n",
    "    #mask_tempdiff = np.zeros_like(temporal_diff)\n",
    "    for t_i in range(arrivals.shape[1]):\n",
    "        temporal_diff[:, :t_i, t_i] = arrivals[:, t_i] - arrivals[:, :t_i]\n",
    "        #mask_tempdiff[:, :t_i, t_i] = 1.0\n",
    "    mask_tempdiff = (temporal_diff != 0)\n",
    "    \n",
    "    return mask_tempdiff, temporal_diff\n",
    "    ### Create a UsersxTimexTime matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_tdiff, temporal_diff = calc_temporal_differences(events, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglikelihood():\n",
    "    #tdiff = diff(arrivals) * mask[:, 1:]\n",
    "    #A_i = tf.zeros_like(arrivals)\n",
    "    #for i in range(tdiff.shape[0]):\n",
    "    #    A_i[:, i + 1] = tdiff[:, i] * (1 + A[:, i ])\n",
    "    #part1 = tf.log(mu + alpha * ais_tvar)\n",
    "    #part1 = tf.reduce_sum(tf.log(mu + alpha * ais_tvar), axis=1)[:, None]\n",
    "    hist_effects = tf.reduce_sum((tf.exp(-beta[:, :, None] * temp_diff_tvar))*mask_tdiff_tvar, axis=2)\n",
    "    part1 = tf.reduce_sum(tf.log(mu + alpha * hist_effects), axis=1)\n",
    "    #part1 = tf.reduce_sum()\n",
    "    T_max = tf.reduce_max(arrivals_tvar*mask_tvar, axis=1)[:, None]\n",
    "    part2 = mu * T_max\n",
    "    tmp = tf.exp(-beta * ((T_max - arrivals_tvar)*mask_tvar))\n",
    "    p3_tmp = tf.reduce_sum(tmp - tf.constant(1.0, dtype=tf.float64), axis=1)\n",
    "    part3 = (alpha / beta)* p3_tmp[:, None]\n",
    "    \n",
    "    #return part1, part2, part3, part1 - part2 + part3\n",
    "    return tf.reduce_sum(part1 - part2 + part3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = 1\n",
    "alpha = tf.Variable(tf.random_uniform([num_users, 1], dtype=tf.float64), name='alpha')\n",
    "#alpha = tf.Variable(tf.ones([num_users, 1], dtype=tf.float64), name='alpha')\n",
    "beta = tf.Variable(tf.random_uniform([num_users, 1], dtype=tf.float64), name='beta')\n",
    "#beta = tf.Variable(tf.ones([num_users, 1], dtype=tf.float64), name='beta')\n",
    "#beta = tf.constant(1.0, dtype=tf.float64, name='beta')\n",
    "mu = tf.Variable(tf.random_uniform([num_users, 1], dtype=tf.float64), name='mu')\n",
    "lag_mult = tf.Variable(tf.zeros((4,1), dtype=tf.float64), name='lagrangian')\n",
    "#mu = tf.Variable(tf.ones([num_users, 1], dtype=tf.float64), name='mu')\n",
    "penalty = tf.constant(4, dtype=tf.float64)\n",
    "learning_rate = tf.constant(0.00001, dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_max = 4000\n",
    "arrivals_tvar = tf.placeholder(tf.float64, [None, T_max])\n",
    "mask_tvar = tf.placeholder(tf.float64, [None, T_max])\n",
    "temp_diff_tvar = tf.placeholder(tf.float64,[None, T_max, T_max])\n",
    "mask_tdiff_tvar = tf.placeholder(tf.float64, [None, T_max, T_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_func():\n",
    "    nloglik = -loglikelihood()\n",
    "    l = tf.reduce_sum(alpha)  + tf.reduce_sum(mu) + tf.reduce_sum(alpha - beta) \n",
    "    regularizer = tf.reduce_sum(tf.square(alpha)) + tf.reduce_sum(tf.square(beta)) + tf.reduce_sum(tf.square(mu))\n",
    "    return nloglik + 0.5*regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ADMM_cost():\n",
    "    nloglik = -loglikelihood()\n",
    "    regularizer = (tf.reduce_sum(tf.square(alpha)) + tf.reduce_sum(tf.square(beta)) + \n",
    "                   tf.reduce_sum(tf.square(mu)) + tf.reduce_sum(tf.square(alpha - beta)))\n",
    "    constraints = tf.stack([tf.reduce_sum(alpha), tf.reduce_sum(mu), tf.reduce_sum(alpha - beta), tf.reduce_sum(beta)], name='constraints', axis=0)\n",
    "    lagrangian = nloglik + tf.reduce_sum(lag_mult[:,0]*constraints) + (penalty/2.0)*regularizer\n",
    "    return lagrangian, constraints, regularizer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ADMM_update():\n",
    "    grad_alpha = optim.compute_gradients(lagrangian, var_list=[alpha])[0][0]\n",
    "    alpha2 = alpha.assign(alpha - learning_rate * grad_alpha)\n",
    "    \n",
    "    grad_beta = optim.compute_gradients(lagrangian, var_list=[beta])[0][0]\n",
    "    beta2 = beta.assign(beta - learning_rate * grad_beta)\n",
    "\n",
    "    grad_mu = optim.compute_gradients(lagrangian, var_list=[mu])[0][0]\n",
    "    mu2 = mu.assign(mu - learning_rate * grad_mu)\n",
    "    \n",
    "    lag2 = lag_mult.assign((lag_mult[:, 0] + penalty * (constraints))[:, None])\n",
    "    return alpha2, beta2, mu2, lag2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p3 = loglikelihood()\n",
    "p3 = cost_func()\n",
    "#grad = tf.gradients(p3, [alpha, beta, mu])\n",
    "optim = tf.train.GradientDescentOptimizer(0.0001)#.minimize(p3)\n",
    "lagrangian, constraints, regularizer = ADMM_cost()\n",
    "al2, bt2, mu2, lag2 = ADMM_update()\n",
    "ll = loglikelihood()\n",
    "\n",
    "\n",
    "#optim = tf.train.AdamOptimizer()\n",
    "\n",
    "#gr_alpha, gr_beta, gr_mu  = optim.compute_gradients()\n",
    "#gr_alpha = (tf.clip_by_value(gr_alpha[0], 0.01, np.infty), gr_alpha[1])\n",
    "#gr_beta = (tf.clip_by_value(gr_beta[0], 0.01, np.infty), gr_beta[1])\n",
    "#gr_mu = (tf.clip_by_value(gr_mu[0], 0.01, np.infty), gr_mu[1])\n",
    "\n",
    "#minmzr = optim.apply_gradients([gr_alpha,gr_beta, gr_mu])\n",
    "#p1, p2, p3 = loglikelihood()\n",
    "#capped_gvs = [(tf.clip_by_value(grad, 0, 1), var) for grad, var in gvs]\n",
    "#train_op = optim.apply_gradients(capped_gvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9405528609382989 0.6256697059784464 0.2624056148475916\n",
      "[ 3.87395818  1.05551908  1.59496609  2.27899209]\n",
      "0.8951771199841483 0.9827628916829314 0.2618217639754962\n",
      "[ 177.08289643   52.89944463   -1.97943481  179.06233124]\n",
      "0.9325151353408454 1.0247480096180717 0.2525714474523037\n",
      "[ 361.2431181   104.7591663   -20.37714984  381.62026794]\n",
      "0.8831469500440096 0.9613418784679577 0.21848232330454637\n",
      "[ 544.29110865  152.34897165  -37.68691159  581.97802024]\n",
      "0.7581892410783813 0.8117826041474162 0.16049378564227904\n",
      "[ 709.80291262  190.73749849  -51.00864451  760.81155714]\n",
      "0.579934742054835 0.6076901746403106 0.08332558079775985\n",
      "[ 844.58972172  215.52620763  -59.10382471  903.69354643]\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    #learning_rate = 0.0001\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(300):\n",
    "        #print(sess.run(constraints))\n",
    "        #print(sess.run(lag_mult))\n",
    "        #print(sess.run(ll))\n",
    "        #print(i)\n",
    "        #j2 = sess.run(optim.compute_gradients(lagrangian, var_list=[alpha]), feed_dict={arrivals_tvar: np.nan_to_num(events), mask_tvar:mask, temp_diff_tvar: temporal_diff, mask_tdiff_tvar:mask_tdiff}) \n",
    "        #j2 = sess.run(lag_mult[:, 0] - penalty*constraints, feed_dict={arrivals_tvar: np.nan_to_num(events), mask_tvar:mask, temp_diff_tvar: temporal_diff, mask_tdiff_tvar:mask_tdiff}) \n",
    "        #print(j2)\n",
    "        #print(alpha.eval())\n",
    "        j = sess.run([al2,bt2, mu2, lag2], feed_dict={arrivals_tvar: np.nan_to_num(events), mask_tvar:mask, temp_diff_tvar: temporal_diff, mask_tdiff_tvar:mask_tdiff})\n",
    "        if i % 50 == 0:\n",
    "            print(np.asscalar(j[0]), np.asscalar(j[1]), np.asscalar(j[2]))\n",
    "            print(j[3][:, 0])\n",
    "        #print(sess.run(loglikelihood()))\n",
    "        #alpha.assign(alpha - learning_rate * gr_a)\n",
    "        #j = sess.run(gr_b, feed_dict={arrivals_tvar: np.nan_to_num(events), mask_tvar:mask, temp_diff_tvar: temporal_diff, mask_tdiff_tvar:mask_tdiff})\n",
    "        #beta.assign(beta - learning_rate * gr_b)\n",
    "        #mu.assign(mu - learning_rate * gr_m)\n",
    "        #lag_mult.assign(lag_mult - penalty * (constraints))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'alpha/read:0' shape=(1, 1) dtype=float64>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 406.00000167])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
